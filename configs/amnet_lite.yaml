# AMNet-Lite Configuration
# Smaller version with ~20-30M parameters for memory-constrained training

# Model Architecture - Significantly reduced
model:
  name: "AMNet-Lite"
  num_classes: 16
  input_size: [64, 96, 96]  # Reduced input size: D, H, W

  # 2D Branch Configuration - Smaller
  encoder_2d:
    name: "convnext_v2_tiny"  # Much smaller than base
    feature_dim: 256          # Reduced from 1024
    depths: [2, 2, 6, 2]      # Reduced from [3, 3, 27, 3]

  # 3D Branch Configuration - Smaller
  encoder_3d:
    name: "resnet3d_18"       # Reduced from resnet3d_50
    feature_dim: 512          # Reduced from 2048
    layers: [2, 2, 2, 2]      # Reduced from [3, 4, 6, 3]

  # Fusion Configuration - Smaller
  fusion_dim: 128             # Reduced from 512
  scales: [1, 2, 4]           # Reduced from [1, 2, 4, 8]

  # Attention Configuration - Smaller
  attention_heads: 4          # Reduced from 8
  attention_dropout: 0.1

# Training Configuration - Optimized for smaller model
training:
  batch_size: 8               # Can use larger batch with smaller model
  learning_rate: 0.0002       # Slightly higher LR for smaller model
  weight_decay: 0.00001
  max_epochs: 100
  early_stopping: 50

  # Optimizer
  optimizer: "AdamW"
  betas: [0.9, 0.999]

  # Scheduler
  scheduler: "CosineAnnealingLR"
  eta_min: 0.0000001

# Loss Function Weights - Same as original
loss:
  alpha_dice: 1.0
  beta_focal: 0.5
  gamma_boundary: 0.3
  delta_constraint: 0.2

  # Focal loss parameters
  focal_alpha: 1.0
  focal_gamma: 2.0

# Data Configuration
data:
  root_dir: "/media/salam/projects/amos22/data/amos/"
  num_workers: 4              # Reduced workers
  pin_memory: true
  cache_data: false           # Disable caching to save memory

  # Data splits
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15

  # Preprocessing - Reduced window for smaller input
  window_level: 40.0
  window_width: 400.0
  target_spacing: [2.0, 1.5, 1.5]  # Slightly lower resolution

# Data Augmentation - Reduced probability
augmentation:
  probability: 0.6            # Reduced from 0.8

  # Geometric transformations
  rotation_range: [-5, 5]     # Reduced from [-10, 10]
  scaling_range: [0.95, 1.05] # Reduced from [0.9, 1.1]
  flip_probability: 0.5

  # Intensity transformations - Lighter augmentation
  noise_std: 0.05             # Reduced from 0.1
  brightness_range: [-0.05, 0.05]  # Reduced from [-0.1, 0.1]
  contrast_range: [0.9, 1.1]  # Reduced from [0.8, 1.2]

  # Advanced augmentations - Disabled for speed
  elastic_alpha: 0.5
  elastic_sigma: 25.0
  elastic_probability: 0.1    # Reduced from 0.3

  blur_sigma_range: [0.5, 1.0]
  blur_probability: 0.1       # Reduced from 0.3

# Paths Configuration
paths:
  output_dir: "./outputs"
  checkpoint_dir: "./outputs/checkpoints"
  log_dir: "./outputs/logs"
  predictions_dir: "./outputs/predictions"
  visualizations_dir: "./outputs/visualizations"

# Logging Configuration
logging:
  level: "INFO"
  log_interval: 10
  val_interval: 50
  save_checkpoint_interval: 100
  visualize_predictions: true

  # Wandb configuration
  use_wandb: true
  wandb_project: "AMNet-Lite-AbdominalSegmentation"
  wandb_entity: null

# Evaluation Configuration
evaluation:
  metrics: ["dice", "iou", "hd95", "asd", "volume_error"]
  save_predictions: true
  generate_plots: true
  slice_indices: null
  colormap: "custom"

# Inference Configuration
inference:
  batch_size: 1
  use_tta: false
  save_format: "nifti"
  remove_small_objects: true
  min_object_size: 50         # Reduced from 100

# Hardware Configuration
hardware:
  device: "cuda"
  mixed_precision: true
  gradient_accumulation_steps: 1
  max_memory_usage: 0.8       # More conservative memory usage

# Organ Labels - Same as original
organ_labels:
  0: "background"
  1: "spleen"
  2: "right_kidney"
  3: "left_kidney"
  4: "gallbladder"
  5: "esophagus"
  6: "liver"
  7: "stomach"
  8: "aorta"
  9: "IVC"
  10: "portal_vein"
  11: "pancreas"
  12: "right_adrenal"
  13: "left_adrenal"
  14: "duodenum"
  15: "bladder"